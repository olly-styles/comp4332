{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment one - KDD cup 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the smaller datasets into main memory, and split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data...\n",
      "complete..\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sqlalchemy import create_engine # database connection\n",
    "from sklearn import preprocessing  \n",
    "from sklearn import cross_validation\n",
    "\n",
    "# load the data\n",
    "print('loading the data...')\n",
    "projects = pd.read_csv('./data/projects.csv')\n",
    "outcomes = pd.read_csv('./data/outcomes.csv')\n",
    "sample = pd.read_csv('./data/sampleSubmission.csv')\n",
    "print('complete..')\n",
    "\n",
    "# sort the data based on id\n",
    "projects = projects.sort_values(by='projectid')\n",
    "sample = sample.sort_values(by='projectid')\n",
    "outcomes = outcomes.sort_values(by='projectid')\n",
    "\n",
    "# split the training data and testing data\n",
    "dates = np.array(projects.date_posted)\n",
    "train_idx = np.where(dates < '2014-01-01')[0]\n",
    "test_idx = np.where(dates >= '2014-01-01')[0]\n",
    "\n",
    "# fill the missing data\n",
    "projects = projects.fillna(method='pad') # fill the missing hole with the previous observation data\n",
    "\n",
    "# set the target labels\n",
    "labels = np.array(outcomes.is_exciting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get categorical columns from projects and add them to an array projects_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_all_columns = set(projects.columns)\n",
    "projects_numeric_columns = set(projects._get_numeric_data().columns)\n",
    "#projects_numeric_columns.add('date_posted')\n",
    "projects_id_columns = {'projectid', 'teacher_acctid', 'schoolid', 'school_ncesid'}\n",
    "projects_categorial_columns = projects_all_columns.difference(projects_id_columns).difference(projects_numeric_columns)\n",
    "\n",
    "projects_categorial_columns = np.array(list(projects_categorial_columns))\n",
    "projects_categorial_values = np.array(projects[projects_categorial_columns])\n",
    "\n",
    "# encode the category value and reform the original data\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "#Convert first *column* of catagorical data to numeric values\n",
    "projects_data = label_encoder.fit_transform(projects_categorial_values[:,0])\n",
    "\n",
    "#For every other *column* of categorical data, add it to the array \n",
    "for i in range(0, projects_categorial_values.shape[1]):\n",
    "    projects_data = np.column_stack((projects_data, label_encoder.fit_transform(projects_categorial_values[:,i])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Number of recent exciting projects a each teacher has donated to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "disk_engine = create_engine('sqlite:///project1.db') #Create/connect to a database\n",
    "\n",
    "teacher_donations = pd.read_sql_query(\"SELECT donor_acctid, COUNT(DISTINCT donations.projectid) \\\n",
    "                                       FROM donations \\\n",
    "                                       JOIN outcomes \\\n",
    "                                       ON donations.projectid = outcomes.projectid \\\n",
    "                                       WHERE is_teacher_acct='t'\\\n",
    "                                      AND donation_timestamp > '2013-01-01'\\\n",
    "                                       AND is_exciting = 't' \\\n",
    "                                       GROUP BY donor_acctid\",disk_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_COLUMNS = ['projectid','teacher_acctid','schoolid']   # We store the id columns so they will be easy to add and remove\n",
    "X = projects[ID_COLUMNS]    # Our feature vector contains just ids\n",
    "\n",
    "  \n",
    "X = X.merge(teacher_donations,left_on='teacher_acctid',right_on='donor_acctid',how='left') # Left merge\n",
    "X = X.drop('donor_acctid',axis=1) #Don't need the merged column twice\n",
    "X = X.rename(columns={'projectid)': 'num_exciting_donations'})  #Rename the feature\n",
    "X['num_exciting_donations'] = X['num_exciting_donations'].fillna(0)  #Any nan values mean 0 donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of exciting projects this school has had within the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = projects.merge(outcomes)\n",
    "num_exciting_projects = merged[(merged.is_exciting=='t') & (merged.date_posted > '2013-01-01')].groupby('schoolid').count()\n",
    "num_exciting_projects = num_exciting_projects.reset_index()\n",
    "num_exciting_projects = num_exciting_projects[['schoolid','is_exciting']]\n",
    "num_exciting_projects =  num_exciting_projects.rename(columns={'is_exciting': 'num_exciting_projects'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to feature vector X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.merge(num_exciting_projects,left_on='schoolid',right_on='schoolid',how='left') # Left merge\n",
    "X['num_exciting_projects'] = X['num_exciting_projects'].fillna(0)  #Any nan values mean 0 donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of exciting projects this teacher has had within the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_exciting_projects_teach = merged[(merged.is_exciting=='t') & (merged.date_posted > '2013-01-01')].groupby('teacher_acctid').count()\n",
    "num_exciting_projects_teach = num_exciting_projects_teach.reset_index()\n",
    "num_exciting_projects_teach = num_exciting_projects_teach[['teacher_acctid','is_exciting']]\n",
    "num_exciting_projects_teach =  num_exciting_projects_teach.rename(columns={'is_exciting': 'num_exciting_projects_teach'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to the feature vector X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.merge(num_exciting_projects_teach,left_on='teacher_acctid',right_on='teacher_acctid',how='left') # Left merge\n",
    "X['num_exciting_projects_teach'] = X['num_exciting_projects_teach'].fillna(0)  #Any nan values mean 0 donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay cluster success percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustered = pd.read_csv('.data/myclusters.csv',names = ['projectid', 'cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to the feature vector X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.merge(clustered,left_on='projectid',right_on='projectid',how='left') # Left merge\n",
    "X['cluster'] = X['cluster'].fillna(0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>num_exciting_donations</th>\n",
       "      <th>num_exciting_projects</th>\n",
       "      <th>num_exciting_projects_teach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bff514104264a6b798356fdd893</td>\n",
       "      <td>3414541eb63108700b188648f866f483</td>\n",
       "      <td>cbaae3265eda78d330cb8ab1a9217071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002d691c05c51a5fdfbb2baef0ba25</td>\n",
       "      <td>7ad6abc974dd8b62773f79f6cbed48d5</td>\n",
       "      <td>56502bae9e97bab5eb54f9001878f469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000b38bbc7252972f7984848cf58098</td>\n",
       "      <td>e1aa1ae5301d0cda860c4d9c89c24919</td>\n",
       "      <td>30fcfca739b17be54ce3f1ee46980340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000ee613c92ddc5298bf63142996a5c</td>\n",
       "      <td>e0c0a0214d3c2cfdc0ab6639bc3c5342</td>\n",
       "      <td>38bb0d62aa613c2f933de56c9df855b7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  00002bff514104264a6b798356fdd893  3414541eb63108700b188648f866f483   \n",
       "2  00002d691c05c51a5fdfbb2baef0ba25  7ad6abc974dd8b62773f79f6cbed48d5   \n",
       "3  0000b38bbc7252972f7984848cf58098  e1aa1ae5301d0cda860c4d9c89c24919   \n",
       "4  0000ee613c92ddc5298bf63142996a5c  e0c0a0214d3c2cfdc0ab6639bc3c5342   \n",
       "\n",
       "                           schoolid  num_exciting_donations  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c                      61   \n",
       "1  cbaae3265eda78d330cb8ab1a9217071                       0   \n",
       "2  56502bae9e97bab5eb54f9001878f469                       0   \n",
       "3  30fcfca739b17be54ce3f1ee46980340                       0   \n",
       "4  38bb0d62aa613c2f933de56c9df855b7                       0   \n",
       "\n",
       "   num_exciting_projects  num_exciting_projects_teach  \n",
       "0                      6                            5  \n",
       "1                      0                            0  \n",
       "2                      0                            0  \n",
       "3                      0                            0  \n",
       "4                      2                            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of essay feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_essay_length = pd.read_sql_query('SELECT projectid, length(essay) from essays',disk_engine)\n",
    "df_essay_length = df_essay_length.sort_values(by = 'projectid')\n",
    "df_essay_length = df_essay_length.fillna(0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the features into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_exciting_donations = np.array(X['num_exciting_donations'])\n",
    "num_exciting_projects =  np.array(X['num_exciting_projects'])\n",
    "num_exciting_projects_teach =  np.array(X['num_exciting_projects_teach'])\n",
    "cluster_score =  np.array(X['cluster'])\n",
    "essays = np.array(df_essay_length['length(essay)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocess the features\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()  \n",
    "\n",
    "essays = max_abs_scaler.fit_transform(essays.reshape(-1,1)) #Reshape essays and scale  \n",
    "projects_data = np.column_stack((projects_data, essays))  #Add it as a column aka feature\n",
    "\n",
    "num_exciting_donations = max_abs_scaler.fit_transform(num_exciting_donations.reshape(-1,1)) #Reshape and scale  \n",
    "projects_data = np.column_stack((projects_data, num_exciting_donations))  #Add it as a column aka feature\n",
    "\n",
    "num_exciting_projects = max_abs_scaler.fit_transform(num_exciting_projects.reshape(-1,1)) #Reshape and scale  \n",
    "projects_data = np.column_stack((projects_data, num_exciting_projects))  #Add it as a column aka feature\n",
    "\n",
    "cluster_score = max_abs_scaler.fit_transform(cluster_score.reshape(-1,1)) #Reshape and scale  \n",
    "projects_data = np.column_stack((projects_data, cluster_score))  #Add it as a column aka feature\n",
    "\n",
    "# Adding the 'num_exciting_projects_teach' results in overfitting and a poor leaderboard score, so it is commented out \n",
    "\n",
    "\n",
    "#num_exciting_projects_teach = max_abs_scaler.fit_transform(num_exciting_projects_teach.reshape(-1,1)) #Reshape and scale  \n",
    "#projects_data = np.column_stack((projects_data, num_exciting_projects_teach))  #Add it as a column aka feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the numeric columns from projects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projects_useful_numeric_columns = projects_numeric_columns.difference(\n",
    "    {'school_zip','school_latitude','school_longitude','school_ncesid'})\n",
    "\n",
    "for i in range(len(projects_useful_numeric_columns)):\n",
    "    column = np.array(projects[list(projects_useful_numeric_columns)[i]]).reshape(-1,1)\n",
    "    column = max_abs_scaler.fit_transform(column)   #Normalize\n",
    "    projects_data = np.column_stack((projects_data, column))\n",
    "    \n",
    "projects_data = projects_data.astype(float)     #Convert everything to floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE for the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "enc = OneHotEncoder(categorical_features=np.arange(24)) #Encode categorial features only\n",
    "enc.fit(projects_data)\n",
    "projects_data = enc.transform(projects_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_data = projects_data.tocsr() #Convert to martix that supports indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predicting\n",
    "train = projects_data[train_idx]\n",
    "test = projects_data[test_idx]\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train, labels=='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 3 fold cross validation on the training set. This takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79283973,  0.78812177,  0.79099877])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross_validation.cross_val_score(clf, train, labels=='t', scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the prediction, add linear time decay, and save the predictions as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_date_mapping = projects[['projectid','date_posted']]\n",
    "project_date_mapping.set_index('projectid')\n",
    "\n",
    "# Calculate the decay\n",
    "decay = sample.merge(project_date_mapping).drop('is_exciting',axis=1)\n",
    "decay = decay.sort_values(by='date_posted')\n",
    "decay['start_date'] = pd.Timestamp('2014-01-01')\n",
    "decay['date_posted'] = pd.to_datetime(decay['date_posted'])\n",
    "decay['factor'] = (decay.start_date-decay.date_posted).astype('timedelta64[D]')+132\n",
    "decay = decay.drop(['date_posted','start_date'],axis=1)\n",
    "decay = decay.set_index('projectid')\n",
    "\n",
    "# Predict propability of exciting \n",
    "preds = clf.predict_proba(test)[:,1]\n",
    "\n",
    "# Apply the decay and save to csv\n",
    "sample = sample.set_index('projectid')\n",
    "sample = sample.join(decay)\n",
    "sample['is_exciting'] = preds * sample['factor']\n",
    "sample = sample.drop('factor',axis=1)\n",
    "sample.to_csv('predictions.csv', index = True)\n",
    "sample = sample.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
